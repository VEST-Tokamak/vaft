#!/usr/bin/env python3
"""
Mines and plots stability analysis data generated by run_parallel_dcon.py.
Data is expected to be in: <base_data_path>/<shot>/stability_analysis/<gfile_short_id>/...
where <gfile_short_id> is the numerical part of the gfile name (e.g., "00328").
"""
import os
import argparse
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
import sys
import logging
import glob
import xarray as xr
import re
import numpy as np

# --- Configuration ---
DEFAULT_PATH = "/srv/vest.filedb/public"
IDEAL_N_SCAN = [1, 2, 3, 4, 5, 6]
RESIST_N_SCAN = [1, 2]

def find_stability_dirs(base_path):
    # find all .../{shot}/linear_stability/{time} directory in base_path
    stability_dirs = glob.glob(os.path.join(base_path, "*", "linear_stability", "*"))
    # Filter only directories with integer time values
    filtered_dirs = [d for d in stability_dirs if os.path.basename(d).isdigit()]
    return filtered_dirs   

def extract_delta_w(stability_dir):
    """Extract delta W values from dcon output files for a given stability directory."""
    dcon_dir = os.path.join(stability_dir, "dcon")
    if not os.path.exists(dcon_dir):
        return None
    
    delta_w_values = {}
    for n_dir in glob.glob(os.path.join(dcon_dir, "nn=*")):
        n = int(os.path.basename(n_dir).split('=')[1])
        dcon_file = os.path.join(n_dir, f"dcon_output_n{n}.nc")
        
        if os.path.exists(dcon_file):
            try:
                ds = xr.open_dataset(dcon_file)
                W_t = ds["W_t_eigenvalue"].values[0, 0]
                delta_w_values[n] = W_t
                print(f"[INFO] Extracted W_t={W_t} for n={n} from {dcon_file}")
            except Exception as e:
                print(f"[ERROR] Failed to read {dcon_file}: {e}")
                continue
    
    return delta_w_values

def extract_delta_prime_from_nc(stability_dir: str, code_name: str, n_mode: int) -> float | None:
    """
    Extracts the 'innermost' Delta_prime value from an .nc file for rdcon or stride.
    The .nc file is expected to be in stability_dir/code_name/nn={n_mode}/
    The variable name is assumed to be "Delta_prime".
    The "innermost" value is heuristically extracted, attempting to mimic [0,0,0] style access.
    """
    code_specific_dir = os.path.join(stability_dir, code_name)
    nn_mode_dir = os.path.join(code_specific_dir, f"nn={n_mode}")

    nc_file_name_pattern = f"{code_name}_output_n{n_mode}.nc"
    nc_file_path = os.path.join(nn_mode_dir, nc_file_name_pattern)

    if not os.path.exists(nc_file_path):
        generic_nc_files = glob.glob(os.path.join(nn_mode_dir, "*.nc"))
        if generic_nc_files:
            nc_file_path = generic_nc_files[0]
            if len(generic_nc_files) > 1:
                print(f"[WARN] Multiple .nc files found in {nn_mode_dir} for {code_name} n={n_mode}. Using {os.path.basename(nc_file_path)}.")
            else:
                print(f"[INFO] Specific file '{nc_file_name_pattern}' not found. Using '{os.path.basename(nc_file_path)}' in {nn_mode_dir} for {code_name} n={n_mode}.")
        else:
            # print(f"[DEBUG] No .nc file found in {nn_mode_dir} for {code_name}, n={n_mode}.") # Less verbose
            return None # No NC file, cannot extract

    try:
        with xr.open_dataset(nc_file_path) as ds:
            if "Delta_prime" not in ds.variables:
                print(f"[ERROR] Variable 'Delta_prime' not found in {nc_file_path}.")
                return None

            delta_prime_var = ds["Delta_prime"]
            extracted_value = None

            if delta_prime_var.ndim == 0: # Scalar
                extracted_value = delta_prime_var.item()
            elif delta_prime_var.ndim >= 3 and all(s > 0 for s in delta_prime_var.shape[:3]):
                extracted_value = delta_prime_var.data[0, 0, 0].item()
            elif delta_prime_var.ndim > 0 and delta_prime_var.size > 0:
                # Fallback: try to take the very first element by repeatedly indexing [0]
                current_val = delta_prime_var.data
                try:
                    for _ in range(delta_prime_var.ndim):
                        if hasattr(current_val, '__getitem__') and len(current_val) > 0: # Check if indexable and not empty
                           current_val = current_val[0]
                        else: # Not indexable further or became empty along the way
                           break 
                    if np.isscalar(current_val):
                        extracted_value = float(current_val)
                except IndexError: # Handle cases where indexing [0] fails (e.g. on an already scalar value after some indexing)
                     if np.isscalar(current_val):
                        extracted_value = float(current_val)


            if extracted_value is not None:
                print(f"[INFO] Extracted Delta_prime={extracted_value} for {code_name} n={n_mode} from {os.path.basename(nc_file_path)}")
                return extracted_value
            else:
                print(f"[ERROR] Delta_prime in {os.path.basename(nc_file_path)} (shape {delta_prime_var.shape}) could not be interpreted as a scalar value via common indexing methods.")
                return None

    except FileNotFoundError:
        # This case should be caught by the os.path.exists check and generic_nc_files logic,
        # but kept for robustness if nc_file_path is somehow set to a non-existent file later.
        print(f"[WARN] NC file {os.path.basename(nc_file_path)} not found in {nn_mode_dir} during access attempt.")
        return None
    except Exception as e:
        print(f"[ERROR] Failed to read/process {os.path.basename(nc_file_path)} in {nn_mode_dir} for Delta_prime ({code_name} n={n_mode}): {e}")
        return None

def extract_sas_flag_from_in_file(stability_dir: str, code_name: str) -> str | None:
    """
    Extracts the 'sas_flag' value from the corresponding .in file (e.g., dcon.in).
    It checks within the first 'nn' directory found, assuming the flag is consistent.
    """
    code_specific_dir = os.path.join(stability_dir, code_name)
    nn_dirs = glob.glob(os.path.join(code_specific_dir, "nn=*"))
    if not nn_dirs:
        return None  # No nn directories found

    # Sort to get a predictable order (e.g., nn=1 first)
    target_dir = sorted(nn_dirs)[0]
    
    in_file_name = f"{code_name}.in"
    in_file_path = os.path.join(target_dir, in_file_name)

    if not os.path.exists(in_file_path):
        print(f"[INFO] Input file not found: {in_file_path}")
        return None

    try:
        with open(in_file_path, 'r') as f:
            for line in f:
                # Use regex for robust matching (ignores whitespace and case)
                match = re.search(r'^\s*sas_flag\s*=\s*([tf])', line, re.IGNORECASE)
                if match:
                    flag_value = match.group(1).lower()
                    print(f"[INFO] Found sas_flag='{flag_value}' in {in_file_path}")
                    return flag_value
    except Exception as e:
        print(f"[ERROR] Could not read or parse {in_file_path}: {e}")
        return None
    
    return None  # Flag not found in the file

def extract_ca1(stability_dir: str) :
    """
    -> tuple[np.ndarray, np.ndarray] | (None, None)
    if it is well extracted, it returns [psin array, ca1 array]
    if it falis, it returns just tuple of none.
    Extracts the ca1 profile and corresponding psi from dcon_output_n1.nc.
    Returns two numpy arrays: psi, ca1.
    """
    nc_dir = os.path.join(stability_dir, 'rdcon', 'nn=1')
    nc_file = os.path.join(nc_dir, 'rdcon_output_n1.nc')
    if not os.path.exists(nc_file):
        print(f"[ERROR] nc file not found: {nc_file}")
        return None, None
    try:
        ds = xr.open_dataset(nc_file)
        psi = ds['psi_n'].values
        ca1 = ds['ca1'].values
        print(f"[INFO] Extracted ca1 profile from {nc_file}")
        return np.array(psi), np.array(ca1)
    except Exception as e:
        print(f"[ERROR] Failed to extract ca1: {e}")
        return None, None

def extract_qlim_qa(stability_dir: str):
    """
    Extracts the q_lim values from the {dcon/rdcon/stride}_output_n{n}.nc file
    """
    # load q_lim from 
    nc_dir = os.path.join(stability_dir, 'dcon', 'nn=1')
    nc_file = os.path.join(nc_dir, 'dcon_output_n1.nc')
    if not os.path.exists(nc_file):
        print(f"[ERROR] nc file not found: {nc_file}")
        return None, None
    try:
        ds = xr.open_dataset(nc_file)
        qlim = ds.qlim
        qa = ds.qa
        return qlim, qa
    except Exception as e:
        print(f"[ERROR] Failed to extract q_lim: {e}")
        return None, None

# --- Main Function ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Generate stability analysis history Excel file')
    parser.add_argument('--base_path', type=str, default=DEFAULT_PATH, help='Base directory path to search for stability analysis data')
    args = parser.parse_args()

    opt = 0 # 원하는 샷 개수 제한 (0 이하이면 제한 없음)

    # Find all stability analysis directories
    stability_dirs = find_stability_dirs(args.base_path)

    # 샷 번호 추출
    shot_numbers = [int(os.path.basename(os.path.dirname(os.path.dirname(d)))) for d in stability_dirs]
    unique_shots = sorted(set(shot_numbers))

    if opt > 0:
        selected_shots = unique_shots[:opt]
        filtered_stability_dirs = [d for d in stability_dirs if int(os.path.basename(os.path.dirname(os.path.dirname(d)))) in selected_shots]
    else:
        filtered_stability_dirs = stability_dirs

    print(f"Number of stability directories (filtered): {len(filtered_stability_dirs)}")
    
    # Create a list to store all data
    all_data = []
    
    for i, stability_dir in enumerate(filtered_stability_dirs):
        print(f"{i+1}/{len(filtered_stability_dirs)}: {stability_dir}")
        
        # Extract shot and time from path
        path_parts = stability_dir.split(os.sep)
        shot = int(path_parts[-3])  # shot number as integer
        time = int(path_parts[-1])  # time slice as integer
        
        # Extract delta W values
        delta_w_values = extract_delta_w(stability_dir)

        # Extract balloning index from dcon.out
        
        # Extract sas_flag from dcon.in
        dcon_sas_flag = extract_sas_flag_from_in_file(stability_dir, "dcon")
        rdcon_sas_flag = extract_sas_flag_from_in_file(stability_dir, "rdcon")
        stride_sas_flag = extract_sas_flag_from_in_file(stability_dir, "stride")

        # Extract tearing indices (Delta_prime) for rdcon and stride
        tearing_indices = {}
        for n_val in RESIST_N_SCAN:
            rdcon_dp = extract_delta_prime_from_nc(stability_dir, "rdcon", n_val)
            tearing_indices[f'tearing_index_rdcon_n{n_val}'] = rdcon_dp
            
            stride_dp = extract_delta_prime_from_nc(stability_dir, "stride", n_val)
            tearing_indices[f'tearing_index_stride_n{n_val}'] = stride_dp

        # Ballooning stability
        psi, ca1 = extract_ca1(stability_dir)
        if psi is not None and ca1 is not None:
            mask = psi > 0.5
            neg_idx = np.where((ca1 < 0) & mask)[0]
            if neg_idx.size > 0:
                ballooning_stab = 'Unstable'
                ballooning_index = float(psi[neg_idx[0]])
            else:
                ballooning_stab = 'Stable'
                ballooning_index = -1.0
        else:
            ballooning_stab = None
            ballooning_index = None

        # qlim, qa 추출
        qlim, qa = extract_qlim_qa(stability_dir)
        if qlim is not None:
            try:
                qlim_val = float(qlim.values.item()) if hasattr(qlim, 'values') else float(qlim)
            except Exception:
                qlim_val = None
        else:
            qlim_val = None
        if qa is not None:
            try:
                qa_val = float(qa.values.item()) if hasattr(qa, 'values') else float(qa)
            except Exception:
                qa_val = None
        else:
            qa_val = None

        # We proceed to add data to all_data even if only some values are found
        # but we need at least delta_w or some tearing_indices to make the row meaningful.
        if delta_w_values or any(v is not None for v in tearing_indices.values()):
            data = {'shot': shot, 'time [ms]': time}
            # Ideal stability
            if delta_w_values:
                all_positive = all(value > 0 for value in delta_w_values.values())
                any_large_value = any(abs(value) >= 100 for value in delta_w_values.values())
                if any_large_value:
                    data['ideal_stability'] = "Error"
                else:
                    data['ideal_stability'] = "Stable" if all_positive else "Unstable"
                data.update({f'delta_w_n{n}': delta_w_values.get(n, None) for n in IDEAL_N_SCAN})
            else:
                data['ideal_stability'] = None
                data.update({f'delta_w_n{n}': None for n in IDEAL_N_SCAN})
                
            data.update(tearing_indices)
            
            # Add resistive stability based on tearing indices
            tearing_values = [v for v in tearing_indices.values() if v is not None]
            if tearing_values:
                any_positive = any(value > 0 for value in tearing_values)
                any_large_value = any(abs(value) >= 1000 for value in tearing_values)
                if any_large_value:
                    data['resistive_stability'] = "Error"
                else:
                    data['resistive_stability'] = "Stable" if not any_positive else "Unstable"
            else:
                data['resistive_stability'] = None

            # Ballooning
            data['ballooning_stability'] = ballooning_stab
            data['ballooning_unstable_index'] = ballooning_index

            # qlim, qa
            data['qlim'] = qlim_val
            data['qa'] = qa_val

            # save sas
            data['dcon_sas_flag'] = dcon_sas_flag
            data['rdcon_sas_flag'] = rdcon_sas_flag
            data['stride_sas_flag'] = stride_sas_flag

            all_data.append(data)

    # Convert to DataFrame and sort by shot and time
    if all_data:
        df = pd.DataFrame(all_data)
        df = df.sort_values(['shot', 'time [ms]'])
        
        # Reorder columns
        id_cols = ['shot', 'time [ms]', 'ideal_stability', 'resistive_stability']
        ideal_cols = [f'delta_w_n{n}' for n in IDEAL_N_SCAN]
        resist_cols = [f'tearing_index_rdcon_n{n}' for n in RESIST_N_SCAN] + [f'tearing_index_stride_n{n}' for n in RESIST_N_SCAN]
        # sas_cols = ['dcon_sas_flag', 'rdcon_sas_flag', 'stride_sas_flag']
        ballooning_cols = ['ballooning_stability', 'ballooning_unstable_index']
        qlim_qa_cols = ['qlim', 'qa']
        
        # Filter for columns that actually exist in the dataframe to avoid KeyErrors
        final_cols = id_cols + ideal_cols + resist_cols + ballooning_cols + qlim_qa_cols # + sas_cols
        df = df.reindex(columns=[col for col in final_cols if col in df.columns])
        
        # Save to Excel
        output_filename = "stability_history.xlsx"
        df.to_excel(output_filename, index=False)
        print(f"\nSuccessfully generated {output_filename}")
    else:
        print("\nNo stability data found.")
