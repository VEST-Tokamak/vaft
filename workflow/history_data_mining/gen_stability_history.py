#!/usr/bin/env python3
"""
Mines and plots stability analysis data generated by run_parallel_dcon.py.
Data is expected to be in: <base_data_path>/<shot>/stability_analysis/<gfile_short_id>/...
where <gfile_short_id> is the numerical part of the gfile name (e.g., "00328").
"""
import os
import argparse
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
import sys
import logging

# --- Configuration ---
# Adjust this path if your Expdata library is located elsewhere.
# Assumes OMAS/ExperimentData relative to the OMAS directory.
# If this script is in OMAS/, then parent / ExperimentData
DEFAULT_EXPDATA_PATH = Path(__file__).resolve().parent / "ExperimentData"
IDEAL_N_SCAN = [1, 2, 3, 4, 5, 6]
RESIST_N_SCAN = [1, 2]
# --- End Configuration ---

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Dynamically add Expdata path if not found
try:
    import Expdata as Exp
    logging.info("Expdata imported successfully from default PYTHONPATH.")
except ImportError:
    expdata_path_to_try = DEFAULT_EXPDATA_PATH
    if expdata_path_to_try.is_dir() and str(expdata_path_to_try) not in sys.path:
        sys.path.insert(0, str(expdata_path_to_try)) # Prepend to sys.path
        logging.info(f"Added {expdata_path_to_try} to sys.path")
        try:
            import Expdata as Exp
            logging.info("Expdata imported successfully after path modification.")
        except ImportError:
            logging.error(f"Failed to import Expdata from {expdata_path_to_try}. Please ensure it's in PYTHONPATH or set DEFAULT_EXPDATA_PATH correctly.")
            sys.exit(1)
    elif 'Expdata' not in sys.modules: # If path was already there or it's not a dir, but still failed
        logging.error(f"Expdata not found. Searched in PYTHONPATH and tried {DEFAULT_EXPDATA_PATH}. Please install or configure.")
        sys.exit(1)


def extract_data_for_gfile(gfile_data_root_path: Path, reconstructed_gfile_name: str):
    """
    Extracts data for a single gfile, using its dedicated data directory.
    Args:
        gfile_data_root_path (Path): Path to the directory containing data for one gfile
                                     (e.g., .../stability_analysis/00328/).
        reconstructed_gfile_name (str): The full name of the gfile (e.g. "g041520.00328")
                                       Used for record-keeping.
    """
    data_row = {'gfile_name': reconstructed_gfile_name}
    gfile_short_id_str = gfile_data_root_path.name 
    data_row['time_id'] = gfile_short_id_str

    try:
        # For a single gfile's data directory, use Exp.ExperimentalData
        exp_data_item = Exp.ExperimentalData(str(gfile_data_root_path), load=True)
        
        # Helper to get item safely
        def get_item_safe(exp_item, path, item_name_for_log):
            try:
                return exp_item.getItem(path)
            except Exception as e:
                logging.debug(f"Could not get {item_name_for_log} via path '{path}' for {reconstructed_gfile_name}. Error: {e}")
                return float('nan')

        # ip, q0, q95
        # Path 'dcon/nn=1/qlim' from run_parallel_dcon.py for q95
        data_row['q95'] = get_item_safe(exp_data_item, 'dcon/nn=1/qlim', 'q95')
        
        # For ip and q0, paths are speculative. Adjust if Expdata stores them differently.
        data_row['ip'] = get_item_safe(exp_data_item, 'dcon/nn=1/global_quantities/ip', 'ip') 
        data_row['q0'] = get_item_safe(exp_data_item, 'dcon/nn=1/global_quantities/q_axis', 'q0')

        # DCON deltaW
        for n_ideal in IDEAL_N_SCAN:
            path = f'dcon/nn={n_ideal}/W_t_eigenvalue/0/0'
            data_row[f'dcon_deltaW_n{n_ideal}'] = get_item_safe(exp_data_item, path, f'dcon_deltaW_n{n_ideal}')

        # RDCON and STRIDE DeltaPrime
        for n_resist in RESIST_N_SCAN:
            rdcon_path = f'rdcon/nn={n_resist}/Delta_prime/0/0/0'
            stride_path = f'stride/nn={n_resist}/Delta_prime/0/0/0'
            data_row[f'rdcon_DeltaPrime_n{n_resist}'] = get_item_safe(exp_data_item, rdcon_path, f'rdcon_DeltaPrime_n{n_resist}')
            data_row[f'stride_DeltaPrime_n{n_resist}'] = get_item_safe(exp_data_item, stride_path, f'stride_DeltaPrime_n{n_resist}')
        
        return data_row

    except Exception as e:
        logging.error(f"Error initializing Exp.ExperimentalData for {gfile_data_root_path} ({reconstructed_gfile_name}): {e}")
        data_row_error = {'gfile_name': reconstructed_gfile_name, 'time_id': gfile_short_id_str}
        data_row_error.update({k: float('nan') for k in ['ip', 'q0', 'q95']})
        for n_ideal in IDEAL_N_SCAN: data_row_error[f'dcon_deltaW_n{n_ideal}'] = float('nan')
        for n_resist in RESIST_N_SCAN:
            data_row_error[f'rdcon_DeltaPrime_n{n_resist}'] = float('nan')
            data_row_error[f'stride_DeltaPrime_n{n_resist}'] = float('nan')
        return data_row_error


def mine_shot_data(shot_number: int, base_data_dir: Path):
    shot_analysis_path = base_data_dir / str(shot_number) / "stability_analysis"
    if not shot_analysis_path.is_dir():
        logging.warning(f"Stability analysis directory not found: {shot_analysis_path}")
        return pd.DataFrame()

    all_gfile_records = []
    gfile_subdirs = [d for d in shot_analysis_path.iterdir() if d.is_dir()]

    if not gfile_subdirs:
        logging.info(f"No gfile data subdirectories found in {shot_analysis_path}")
        return pd.DataFrame()

    for gfile_dir_path in gfile_subdirs:
        gfile_short_id = gfile_dir_path.name 
        
        # Reconstruct gfile name: g{shot:06d}.{short_id_padded_5_digits}
        # short_id from dir name might be "328". Pad to "00328" for typical gfile time format.
        time_id_padded = gfile_short_id.zfill(5) 
        reconstructed_gfile_name = f"g{shot_number:06d}.{time_id_padded}"
        
        record = extract_data_for_gfile(gfile_dir_path, reconstructed_gfile_name)
        if record:
            all_gfile_records.append(record)

    return pd.DataFrame(all_gfile_records)


def plot_mined_data(df: pd.DataFrame, shot_number: int, plots_output_dir: Path):
    if df.empty:
        logging.info(f"No data to plot for shot {shot_number}.")
        return

    plots_output_dir.mkdir(parents=True, exist_ok=True)
    
    df_sorted = df.copy()
    try: # Try sorting by time_id as numeric if possible
        df_sorted['time_id_numeric'] = pd.to_numeric(df_sorted['time_id'])
        df_sorted = df_sorted.sort_values(by='time_id_numeric').drop(columns=['time_id_numeric'])
        x_axis_label = "Time ID (numeric)"
    except ValueError: # Otherwise, treat as string and sort lexicographically
        df_sorted = df_sorted.sort_values(by='time_id')
        x_axis_label = "Time ID (gfile short_id)"
        logging.debug("Time ID for plotting treated as string/categorical.")

    plot_configs = [
        ('dcon_deltaW', 'DCON Delta W', IDEAL_N_SCAN, 'dcon_deltaW_n'),
        ('rdcon_DeltaPrime', 'RDCON Delta Prime', RESIST_N_SCAN, 'rdcon_DeltaPrime_n'),
        ('stride_DeltaPrime', 'STRIDE Delta Prime', RESIST_N_SCAN, 'stride_DeltaPrime_n')
    ]

    for base_name, y_label_base, n_scan, col_prefix in plot_configs:
        plt.figure(figsize=(12, 7))
        has_data_for_plot = False
        for n_val in n_scan:
            col_name = f'{col_prefix}{n_val}'
            if col_name in df_sorted.columns and not df_sorted[col_name].isnull().all():
                plt.plot(df_sorted['time_id'].astype(str), df_sorted[col_name], marker='o', linestyle='-', label=f'n={n_val}')
                has_data_for_plot = True
        
        if has_data_for_plot:
            plt.xlabel(x_axis_label)
            plt.ylabel(y_label_base)
            plt.title(f"Shot {shot_number}: {y_label_base} vs. Time ID")
            plt.xticks(rotation=45, ha="right")
            plt.legend()
            plt.grid(True)
            plt.tight_layout()
            plt.savefig(plots_output_dir / f"shot_{shot_number}_{base_name}.png")
        else:
            logging.info(f"No data to plot for {base_name} for shot {shot_number}")
        plt.close()

    single_param_plots = [ ('ip', 'Plasma Current (kA)'), ('q0', 'q on Axis (q0)'), ('q95', 'q95') ]
    for col, y_label in single_param_plots:
        if col in df_sorted.columns and not df_sorted[col].isnull().all():
            plt.figure(figsize=(10, 6))
            plt.plot(df_sorted['time_id'].astype(str), df_sorted[col], marker='o', linestyle='-')
            plt.xlabel(x_axis_label)
            plt.ylabel(y_label)
            plt.title(f"Shot {shot_number}: {y_label} vs. Time ID")
            plt.xticks(rotation=45, ha="right")
            plt.grid(True)
            plt.tight_layout()
            plt.savefig(plots_output_dir / f"shot_{shot_number}_{col}.png")
            plt.close()
        else:
            logging.debug(f"No data for {col} to plot for shot {shot_number}.")
            
    logging.info(f"Plots for shot {shot_number} saved to {plots_output_dir}")

def main():
    parser = argparse.ArgumentParser(
        description="Mine and plot stability analysis data from specified shot directories.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument("shots", metavar="SHOT", type=int, nargs="+", help="Shot numbers to process.")
    parser.add_argument("--base_data_dir", type=str, default="public",
                        help="Base directory where shot data (e.g., public/<shot>/stability_analysis) is stored.")
    parser.add_argument("--plots_output_dir", type=str, default="mined_stability_plots",
                        help="Directory to save generated plots and summary CSV.")
    parser.add_argument("--expdata_lib_path", type=str, default=str(DEFAULT_EXPDATA_PATH),
                        help="Path to the Expdata library directory, if not in PYTHONPATH or standard relative location.")
    parser.add_argument("--debug", action="store_true", help="Enable debug logging for data extraction details.")

    args = parser.parse_args()

    if args.debug: logging.getLogger().setLevel(logging.DEBUG)
    else: logging.getLogger().setLevel(logging.INFO)


    # Handle Expdata library path if a custom one is provided
    custom_expdata_path = Path(args.expdata_lib_path)
    if custom_expdata_path.is_dir() and str(custom_expdata_path) != str(DEFAULT_EXPDATA_PATH) and str(custom_expdata_path) not in sys.path:
        sys.path.insert(0, str(custom_expdata_path))
        logging.info(f"Using custom Expdata path: {custom_expdata_path}")
        try: # Re-test import
            global Exp
            import Expdata as Exp_custom
            Exp = Exp_custom # Use the newly imported module
            logging.info("Expdata re-imported successfully from custom path.")
        except ImportError:
            logging.error(f"Failed to import Expdata from specified custom path: {custom_expdata_path}. Exiting.")
            sys.exit(1)
    elif 'Exp' not in globals() or Exp is None : # If initial import failed and custom path didn't fix it or wasn't different
         logging.error(f"Expdata module could not be loaded. Check DEFAULT_EXPDATA_PATH or provide a valid --expdata_lib_path. Current default: {DEFAULT_EXPDATA_PATH}")
         sys.exit(1)


    base_data_path = Path(args.base_data_dir)
    plots_base_output_dir = Path(args.plots_output_dir)
    plots_base_output_dir.mkdir(parents=True, exist_ok=True) # Ensure base plot dir exists

    all_shots_data_list = []

    for shot in args.shots:
        logging.info(f"Processing shot {shot}...")
        df_shot_data = mine_shot_data(shot, base_data_path)
        
        if not df_shot_data.empty:
            logging.info(f"Successfully mined {len(df_shot_data)} records for shot {shot}.")
            df_shot_data['shot'] = shot # Add shot number for combined analysis
            all_shots_data_list.append(df_shot_data)
            
            shot_specific_plots_dir = plots_base_output_dir / str(shot)
            plot_mined_data(df_shot_data, shot, shot_specific_plots_dir)
        else:
            logging.warning(f"No data mined for shot {shot}.")

    if all_shots_data_list:
        combined_df = pd.concat(all_shots_data_list, ignore_index=True)
        csv_output_path = plots_base_output_dir / "mined_stability_summary.csv"
        try:
            combined_df.to_csv(csv_output_path, index=False)
            logging.info(f"Combined data for all processed shots saved to {csv_output_path}")
            logging.info(f"Summary of combined data (first 5 rows):
{combined_df.head()}")
        except Exception as e:
            logging.error(f"Failed to save combined data to CSV: {e}")
    else:
        logging.info("No data was mined from any of the specified shots.")

if __name__ == "__main__":
    main() 